{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2. Data Preparation v2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["zFtS9jcpKRZk","nOQMeUlfKM8P","5lt1N2WgKV_t","rs2OM95JKUMk","8nYSTXgvKpnv","00aDNenr6M7t","kzRAaCzswSSV","pQirz5iTwNq8","Zjhy95clwiUT","EHe2AtQ1wZ1I","hCCQWip6w62f","mu_ldWqvxe5b","E7B9vY4msQiI","47kZwnsmsWXP","bQGFAdT5KcdR","mS4KTLUt0hcu","qBX-5WkP0pqC","xbF-foAm0xmt","dEwSiUbYt4Hw","VQapNlnM3H2D","U00ySisyuEGJ","CHMqqf_Pupx3"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"zFtS9jcpKRZk","colab_type":"text"},"cell_type":"markdown","source":["### Access to Google Drive folders"]},{"metadata":{"id":"SZnovfsXZZKp","colab_type":"code","outputId":"3f21a047-139a-450b-aaae-220301385300","executionInfo":{"status":"ok","timestamp":1548703489607,"user_tz":-60,"elapsed":19307,"user":{"displayName":"Adobe PsCs666","photoUrl":"","userId":"12522171119723779979"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"nOQMeUlfKM8P","colab_type":"text"},"cell_type":"markdown","source":["### Constants"]},{"metadata":{"id":"1sJmvOTwb68V","colab_type":"code","colab":{}},"cell_type":"code","source":["images_folder = '/content/gdrive/My Drive/Project/Images_300x450/'\n","models_folder = '/content/gdrive/My Drive/Project/Models/'\n","results_folder = '/content/gdrive/My Drive/Project/Results/'\n","train_folder = 'Train/'\n","validation_folder = 'Validation/'\n","\n","prepared_data_folder = '/content/gdrive/My Drive/Project/Prepared_Data/'\n","\n","titles_file = \"titles\"\n","imdb_id_file = \"imdb_id\"\n","images_file = \"images\"\n","features_file = \"features\"\n","\n","model_InceptionV3 = \"InceptionV3\"\n","model_InceptionV3_with_Fine_Tuning = \"InceptionV3FineTuning\"\n","model_VGG16 = \"VGG16\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"5lt1N2WgKV_t","colab_type":"text"},"cell_type":"markdown","source":["### Libraries\n"]},{"metadata":{"id":"8GLTf3-QVfNd","colab_type":"code","outputId":"f24c55c8-b076-4f86-a6e4-80829eba364e","executionInfo":{"status":"ok","timestamp":1548703495377,"user_tz":-60,"elapsed":25047,"user":{"displayName":"Adobe PsCs666","photoUrl":"","userId":"12522171119723779979"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"cell_type":"code","source":["!pip install h5py pyyaml \n","\n","import os\n","import json\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","from keras.layers import concatenate\n","from keras.preprocessing import image\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from keras.applications.vgg16 import VGG16\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras import layers\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from sklearn.neighbors import NearestNeighbors\n","\n","import tqdm\n","from IPython.display import HTML, display"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.14.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.11.0)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"rs2OM95JKUMk","colab_type":"text"},"cell_type":"markdown","source":["### Parameters"]},{"metadata":{"id":"EhK-BfRFKL7T","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 100\n","model_type = model_InceptionV3_with_Fine_Tuning\n","data_folder = images_folder\n","number_of_recommendations = 5\n","\n","# Parameters for Inception with Fine Tuning\n","epochs_number = 15\n","steps_per_epoch_number = 30\n","validation_steps_number = steps_per_epoch_number / 2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8nYSTXgvKpnv","colab_type":"text"},"cell_type":"markdown","source":["### Functions"]},{"metadata":{"id":"zZMqAbYmIcUS","colab_type":"code","colab":{}},"cell_type":"code","source":["def preprocess_input(x):\n","    x /= 255.\n","    x -= 0.5\n","    x *= 2.\n","    \n","    return x\n","def load_titles(directory):\n","  titles = []\n","\n","  for name in tqdm.tqdm(os.listdir(directory)):\n","    path = os.path.join(directory, name)\n","    if os.path.isdir(path):\n","      continue\n","    title = name.rsplit('.', 1)[0]\n","    title = title.split('-', 1)[1]\n","    titles.append(title)\n","        \n","  return titles\n","\n","def load_imdb_id(directory):\n","  imdb_ids = []\n","\n","  for name in tqdm.tqdm(os.listdir(directory)):\n","    path = os.path.join(directory, name)\n","    if os.path.isdir(path):\n","      continue\n","    imdb_id = name.split('.')[0]\n","    imdb_id = imdb_id.split('-')[0]\n","    imdb_ids.append(imdb_id)\n","        \n","  return imdb_ids\n","\n","\n","def load_images(directory):\n","  images = []\n","\n","  for name in tqdm.tqdm(os.listdir(directory)):\n","    path = os.path.join(directory, name)\n","    if os.path.isdir(path):\n","      continue    \n","    # load an image from file\n","    filename = directory + name\n","    image = load_img(filename, target_size=(299, 299))\n","    # convert the image pixels to a numpy array\n","    image = img_to_array(image)\n","    # reshape data for the model\n","    image = np.expand_dims(image, axis=0)\n","    # prepare the image for the  model\n","    image = preprocess_input(image)\n","   \n","    images.append(image)\n","    \n","  return images\n","\n","def load_features(images):\n","  features = []\n","  \n","  for image in tqdm.tqdm(images):\n","    feature = model2.predict(image).ravel()\n","    features.append(feature)\n","    \n","  return features"],"execution_count":0,"outputs":[]},{"metadata":{"id":"00aDNenr6M7t","colab_type":"text"},"cell_type":"markdown","source":["## Prepare Model"]},{"metadata":{"id":"kzRAaCzswSSV","colab_type":"text"},"cell_type":"markdown","source":["## Prepare to Inception V3 + Fine Tuning Functions "]},{"metadata":{"id":"pQirz5iTwNq8","colab_type":"text"},"cell_type":"markdown","source":["### Load Inception V3 Model + ImageNet weigths"]},{"metadata":{"id":"wNBJnKMGuo8h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"outputId":"3047376a-8889-41aa-8559-0603ca4fab82","executionInfo":{"status":"ok","timestamp":1548703501595,"user_tz":-60,"elapsed":31227,"user":{"displayName":"Adobe PsCs666","photoUrl":"","userId":"12522171119723779979"}}},"cell_type":"code","source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n","    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\n","def load_model_inceptionv3_imagenet():\n","  local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","  pretrained_model = InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=None)\n","  pretrained_model.load_weights(local_weights_file)\n","  \n","  return pretrained_model"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2019-01-28 19:24:56--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.128, 2404:6800:4008:c03::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 87910968 (84M) [application/x-hdf]\n","Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n","\n","/tmp/inception_v3_w 100%[===================>]  83.84M  26.6MB/s    in 3.2s    \n","\n","2019-01-28 19:25:00 (26.6 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"Zjhy95clwiUT","colab_type":"text"},"cell_type":"markdown","source":["### Create new model with additional layers"]},{"metadata":{"id":"WqPpohfVwh1P","colab_type":"code","colab":{}},"cell_type":"code","source":["def prepare_model_to_fine_tuning(pretrained_model):\n","  unfreeze = False\n","\n","  # Unfreeze all models after \"mixed6\"\n","  for layer in pretrained_model.layers:\n","    if unfreeze:\n","      layer.trainable = True\n","    if layer.name == 'mixed6':\n","      unfreeze = True\n","\n","    last_layer = pretrained_model.get_layer('mixed7')\n","    last_output = last_layer.output\n","\n","    ##### Change model - Add 2 fully connected layers #####\n","\n","    # Flatten the output layer to 1 dimension\n","    x = layers.Flatten()(last_output)\n","    # Add a fully connected layer with 1,024 hidden units and ReLU activation\n","    x = layers.Dense(1024, activation='relu')(x)\n","    # Add a dropout rate of 0.2\n","    x = layers.Dropout(0.2)(x)\n","    # Add a fully connected layer with 1,024 hidden units and ReLU activation\n","    x = layers.Dense(1024, activation='relu')(x)\n","    # Add a dropout rate of 0.2\n","    x = layers.Dropout(0.2)(x)\n","    # Add a final sigmoid layer for classification\n","    x = layers.Dense(19, activation='sigmoid')(x)\n","\n","    # Configure and compile the model\n","    model = Model(pretrained_model.input, x)\n","    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.00001, momentum=0.9), metrics=['acc'])\n","\n","    return model "],"execution_count":0,"outputs":[]},{"metadata":{"id":"EHe2AtQ1wZ1I","colab_type":"text"},"cell_type":"markdown","source":["### Prepare Generators"]},{"metadata":{"id":"RIAxHXG_Zc-6","colab_type":"code","colab":{}},"cell_type":"code","source":["def prepare_generators():\n","\n","  # Add our data-augmentation parameters to ImageDataGenerator\n","  train_datagen = ImageDataGenerator(rescale=1./255)\n","\n","  # Note that the validation data should not be augmented!\n","  test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","  train_generator = train_datagen.flow_from_directory(\n","          images_folder + train_folder, # This is the source directory for training images\n","          target_size=(299, 299),  # All images will be resized to 299x299\n","          batch_size=batch_size,\n","          class_mode='categorical')\n","\n","  # Flow validation images in batches of 20 using test_datagen generator\n","  validation_generator = test_datagen.flow_from_directory(\n","          images_folder + validation_folder,\n","          target_size=(299, 299),\n","          batch_size=batch_size,\n","          class_mode='categorical')\n","\n","  return train_generator, validation_generator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hCCQWip6w62f","colab_type":"text"},"cell_type":"markdown","source":["### Fit model using generators"]},{"metadata":{"id":"Fl5XI_urZlCa","colab_type":"code","colab":{}},"cell_type":"code","source":["def fit_model(model, train_generator, validation_generator):\n","\n","  history = model.fit_generator(\n","        train_generator,\n","        steps_per_epoch = steps_per_epoch_number,\n","        epochs = epochs_number,\n","        validation_data=validation_generator,\n","        validation_steps = validation_steps_number,\n","        verbose=1)\n","  \n","  return history, model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mu_ldWqvxe5b","colab_type":"text"},"cell_type":"markdown","source":["### Plot Results of training"]},{"metadata":{"id":"MPmtucotZmSa","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_fine_tuning_results(history):\n","\n","  # Retrieve a list of accuracy results on training and test data\n","  # sets for each training epoch\n","  acc = history.history['acc']\n","  val_acc = history.history['val_acc']\n","\n","  # Retrieve a list of list results on training and test data\n","  # sets for each training epoch\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  # Get number of epochs\n","  epochs = range(len(acc))\n","\n","  fix, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 7))\n","  # Plot training and validation accuracy per epoch\n","  plt.subplot(1, 2, 1)\n","  plt.plot(epochs, acc)\n","  plt.plot(epochs, val_acc)\n","  plt.title('Training and validation accuracy')\n","\n","\n","  # Plot training and validation loss per epoch\n","  plt.subplot(1, 2, 2)\n","  plt.plot(epochs, loss)\n","  plt.plot(epochs, val_loss)\n","  plt.title('Training and validation loss')\n","\n","  plt.savefig(results_folder + \"Fine_Tuning_Results_\" + model_type + \".png\")\n","  None\n","  plt.show()\n","  None"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E7B9vY4msQiI","colab_type":"text"},"cell_type":"markdown","source":["### Remove before added layers used to Fine Tuning"]},{"metadata":{"id":"OFIwq0bPpGKE","colab_type":"code","colab":{}},"cell_type":"code","source":["def remove_added_layers(model):\n","\n","  model_input = model.input\n","  model_output = model.layers[-7].output\n","\n","  model = Model(model_input, model_output)\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"47kZwnsmsWXP","colab_type":"text"},"cell_type":"markdown","source":["### Save pretrained weights"]},{"metadata":{"id":"j-VgDUoVIO-8","colab_type":"code","colab":{}},"cell_type":"code","source":["def save_pretrained_weights(history):\n","  history.model.save_weights(models_folder + model_type + '_weights.h5')\n","\n","  json_model = history.model.to_json()\n","\n","  with open(models_folder + model_type + '.json', 'w') as outfile:\n","      json.dump(json_model, outfile)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bQGFAdT5KcdR","colab_type":"text"},"cell_type":"markdown","source":["## Prepare Model"]},{"metadata":{"id":"mS4KTLUt0hcu","colab_type":"text"},"cell_type":"markdown","source":["### Create Inception V3 model with Fine Tuning"]},{"metadata":{"id":"33PBgn8Q0dbQ","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_InceptionV3_Fine_Tuning_Model():\n","  pretrained_model = load_model_inceptionv3_imagenet()\n","  model = prepare_model_to_fine_tuning(pretrained_model)\n","\n","  train_generator, validation_generator = prepare_generators()\n","  \n","  history, model = fit_model(model, train_generator, validation_generator)\n","  plot_fine_tuning_results(history)\n","  \n","  model = remove_added_layers(model)\n","  save_pretrained_weights(history)\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qBX-5WkP0pqC","colab_type":"text"},"cell_type":"markdown","source":["### Get Model"]},{"metadata":{"id":"d-TSyZ3JUBHX","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_model(model):\n","  switcher={\n","          model_InceptionV3: InceptionV3(weights='imagenet', include_top=False),\n","          model_VGG16: VGG16(weights='imagenet', include_top=False),\n","          model_InceptionV3_with_Fine_Tuning: get_InceptionV3_Fine_Tuning_Model()\n","  }\n","  return switcher.get(model,\"Invalid model\")\n","\n","model = get_model(model_type)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xbF-foAm0xmt","colab_type":"text"},"cell_type":"markdown","source":["## Extract Titles, IDs, Images and Features"]},{"metadata":{"id":"dEwSiUbYt4Hw","colab_type":"text"},"cell_type":"markdown","source":["#### Titles"]},{"metadata":{"id":"lBo0HWJlDSjM","colab_type":"code","colab":{}},"cell_type":"code","source":["titles = load_titles(data_folder)\n","number_of_batches = -(-len(titles) // batch_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-1ZrJ0ieIhbi","colab_type":"code","colab":{}},"cell_type":"code","source":["for idx, i in  tqdm.tqdm(enumerate(range(0, len(titles), batch_size))):\n","  pickle.dump(np.asarray(titles[i:i+batch_size]), open(prepared_data_folder + model_type + \"_\" + titles_file + \"_part_\" + str(idx) + '.p', 'wb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VQapNlnM3H2D","colab_type":"text"},"cell_type":"markdown","source":["#### IMDB ids\n"]},{"metadata":{"colab_type":"code","id":"nxoaV73I3GDV","colab":{}},"cell_type":"code","source":["imdb_ids = load_imdb_id(data_folder)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"y8GvyxcT3GDY","colab":{}},"cell_type":"code","source":["for idx, i in  tqdm.tqdm(enumerate(range(0, len(imdb_ids), batch_size))):\n","  pickle.dump(np.asarray(imdb_ids[i:i+batch_size]), open(prepared_data_folder + model_type + \"_\" + imdb_id_file + \"_part_\" + str(idx) + '.p', 'wb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U00ySisyuEGJ","colab_type":"text"},"cell_type":"markdown","source":["#### Images"]},{"metadata":{"id":"E76oZc8tP0Qs","colab_type":"code","colab":{}},"cell_type":"code","source":["images = load_images(data_folder)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1X0UPApMd7Kf","colab_type":"code","colab":{}},"cell_type":"code","source":["for idx, i in  tqdm.tqdm(enumerate(range(0, len(images), batch_size))):\n","  pickle.dump(np.asarray(images[i:i+batch_size]), open(prepared_data_folder + model_type + \"_\" + images_file + \"_part_\" + str(idx) + '.p', 'wb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CHMqqf_Pupx3","colab_type":"text"},"cell_type":"markdown","source":["#### Features"]},{"metadata":{"id":"VXS0ez-r0dtH","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"ktpvOt27fwGo","colab_type":"code","colab":{}},"cell_type":"code","source":["for idx in range(0, number_of_batches):\n","  filename = prepared_data_folder + model_type + \"_\" + images_file + \"_part_\" + str(idx) + '.p'\n","  loaded_images = pickle.load(open(filename, mode='rb'))\n","  features = load_features(loaded_images)\n","    \n","  pickle.dump(np.asarray(features), open(prepared_data_folder + model_type + \"_\" + features_file + \"_part_\" + str(idx) + '.p', 'wb'))"],"execution_count":0,"outputs":[]}]}